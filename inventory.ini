## TiDB Cluster Part
[tidb_servers]
10.197.197.87
10.197.197.162

[tikv_servers]
10.197.189.66
10.197.248.232
10.197.223.203

[pd_servers]
10.197.176.90
10.197.189.226
10.197.197.234

[spark_master]

[spark_slaves]

[lightning_server]

[importer_server]

## Monitoring Part
# prometheus and pushgateway servers
[monitoring_servers]
10.197.197.87
[grafana_servers]
#10.197.197.87

# node_exporter and blackbox_exporter servers
[monitored_servers]
10.197.197.87
10.197.197.162
10.197.189.66
10.197.248.232
10.197.223.203
10.197.176.90
10.197.189.226
10.197.197.234

[alertmanager_servers]
10.197.197.87

[kafka_exporter_servers]

## Binlog Part
[pump_servers]

[drainer_servers]

## Group variables
[pd_servers:vars]
# location_labels = ["zone","rack","host"]

## Global variables
[all:vars]
deploy_dir = /db

## Connection
# ssh via normal user
ansible_user = pwen

cluster_name = test-cluster

tidb_version = v2.1.2

# process supervision, [systemd, supervise]
process_supervision = systemd

timezone = UTC 

enable_firewalld = False
# check NTP service
enable_ntpd = False
set_hostname = False

## binlog trigger
enable_binlog = False

# kafka cluster address for monitoring, example:
# kafka_addrs = "192.168.0.11:9092,192.168.0.12:9092,192.168.0.13:9092"
kafka_addrs = ""

# zookeeper address of kafka cluster for monitoring, example:
# zookeeper_addrs = "192.168.0.11:2181,192.168.0.12:2181,192.168.0.13:2181"
zookeeper_addrs = ""

# store slow query log into seperate file
enable_slow_query_log = False

# enable TLS authentication in the TiDB cluster
enable_tls = False

# KV mode
deploy_without_tidb = False

# Optional: Set if you already have a alertmanager server.
# Format: alertmanager_host:alertmanager_port
alertmanager_target = ""

grafana_admin_user = "admin"
grafana_admin_password = "admin"


### Collect diagnosis
collect_log_recent_hours = 2

enable_bandwidth_limit = True
# default: 10Mb/s, unit: Kbit/s
collect_bandwidth_limit = 10000
